{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-Me Project\n",
    "Congratulations on reaching the final project of the Robotics Nanodegree! \n",
    "\n",
    "Previously you worked on the Semantic Segmentation lab where you built a deep learning network that locates a particular human target within an image. For this project, you will utilize what you implemented and learned from that lab and extend it to train a deep learning model that will allow a simulated quadcopter to follow around the person that it detects! \n",
    "\n",
    "Most of the code below will be familiar in comparison to the lab with some minor modifications. So you can work off of your existing solution, and modify and improve upon it to train the best possible model for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "We have provided you with a dataset for this project. If you haven't already downloaded the training and validation datasets, you can check out the README for this project's repo for instructions as well.\n",
    "\n",
    "Alternatively, you can also collect your own data and see how well your model can perform on that or tweak your model accordingly. You can check out the \"Collecting Data\" section in the Project Lesson in the Classroom for more details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.keras.python import keras\n",
    "from tensorflow.contrib.keras.python.keras import layers, models\n",
    "\n",
    "from tensorflow import image\n",
    "\n",
    "from utils import scoring_utils\n",
    "from utils.separable_conv2d import SeparableConv2DKeras, BilinearUpSampling2D\n",
    "from utils import data_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN Layers\n",
    "In the Classroom, we discussed the different layers that constitute a fully convolutional network. The following code will intoduce you to the functions that you will be using to build out your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable Convolutions\n",
    "The Encoder for your FCN will essentially require separable convolution layers. Below we have implemented two functions - one which you can call upon to build out separable convolutions or regular convolutions. Each with batch normalization and with the ReLU activation function applied to the layers. \n",
    "\n",
    "While we recommend the use of separable convolutions thanks to their advantages we covered in the Classroom, some of the helper code we will present for your model will require the use for regular convolutions. But we encourage you to try and experiment with each as well!\n",
    "\n",
    "The following will help you create the encoder block and the final model for your architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separable_conv2d_batchnorm(input_layer, filters, strides=1):\n",
    "    output_layer = SeparableConv2DKeras(filters=filters,kernel_size=3, strides=strides,\n",
    "                             padding='same', activation='relu')(input_layer)\n",
    "    \n",
    "    output_layer = layers.BatchNormalization()(output_layer) \n",
    "    return output_layer\n",
    "\n",
    "def conv2d_batchnorm(input_layer, filters, kernel_size=3, strides=1):\n",
    "    output_layer = layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=1, \n",
    "                      padding='same', activation='relu')(input_layer)\n",
    "    \n",
    "    output_layer = layers.BatchNormalization()(output_layer) \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilinear Upsampling\n",
    "The following helper function will help implement the bilinear upsampling layer. Currently, upsampling by a factor of 2 is recommended but you can try out different factors as well. You will use this to create the decoder block later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_upsample(input_layer):\n",
    "    output_layer = BilinearUpSampling2D((2,2))(input_layer)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "In the following cells, we will cover how to build the model for the task at hand. \n",
    "\n",
    "- We will first create an Encoder Block, where you will create a separable convolution layer using an input layer and the size(depth) of the filters as your inputs.\n",
    "- Next, you will create the Decoder Block, where you will create an upsampling layer using bilinear upsampling, followed by a layer concatentaion, and some separable convolution layers.\n",
    "- Finally, you will combine the above two and create the model. In this step you will be able to experiment with different number of layers and filter sizes for each to build your model.\n",
    "\n",
    "Let's cover them individually below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Block\n",
    "Below you will create a separable convolution layer using the separable_conv2d_batchnorm() function. The `filters` parameter defines the size or depth of the output layer. For example, 32 or 64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_block(input_layer, filters, strides):\n",
    "    \n",
    "    # TODO Create a separable convolution layer using the separable_conv2d_batchnorm() function.\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Block\n",
    "The decoder block, as covered in the Classroom, comprises of three steps -\n",
    "\n",
    "- A bilinear upsampling layer using the upsample_bilinear() function. The current recommended factor for upsampling is set to 2.\n",
    "- A layer concatenation step. This step is similar to skip connections. You will concatenate the upsampled small_ip_layer and the large_ip_layer.\n",
    "- Some (one or two) additional separable convolution layers to extract some more spatial information from prior layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoder_block(small_ip_layer, large_ip_layer, filters):\n",
    "    \n",
    "    # TODO Upsample the small input layer using the bilinear_upsample() function.\n",
    "    \n",
    "    # TODO Concatenate the upsampled and large input layers using layers.concatenate\n",
    "    \n",
    "    # TODO Add some number of separable convolution layers\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Now that you have the encoder and decoder blocks ready, you can go ahead and build your model architecture! \n",
    "\n",
    "There are three steps to the following:\n",
    "- Add encoder blocks to build out initial set of layers. This is similar to how you added regular convolutional layers in your CNN lab.\n",
    "- Add 1x1 Convolution layer using conv2d_batchnorm() function. Remember that 1x1 Convolutions require a kernel and stride of 1.\n",
    "- Add decoder blocks for upsampling and skip connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fcn_model(inputs, num_classes):\n",
    "    \n",
    "    # TODO Add Encoder Blocks. \n",
    "    # Remember that with each encoder layer, the depth of your model (the number of filters) increases.\n",
    "\n",
    "    # TODO Add 1x1 Convolution layer using conv2d_batchnorm().\n",
    "    \n",
    "    # TODO: Add the same number of Decoder Blocks as the number of Encoder Blocks\n",
    "    \n",
    "    \n",
    "    # The function returns the output layer of your model. \"x\" is the final layer obtained from the last decoder_block()\n",
    "    return layers.Conv2D(num_classes, 1, activation='softmax', padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The following cells will utilize the model you created and define an ouput layer based on the input and the number of classes.Following that you will define the hyperparameters to compile and train your model!\n",
    "\n",
    "Please Note: For the project you will be working with images of dimensions 160x160x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "image_hw = 160\n",
    "image_shape = (image_hw, image_hw, 3)\n",
    "inputs = layers.Input(image_shape)\n",
    "num_classes = 3\n",
    "\n",
    "# Call fcn_model()\n",
    "output_layer = fcn_model(inputs, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Below you can define and tune your hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0\n",
    "batch_size = 0\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Define the Keras model and compile it for training\n",
    "model = models.Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy')\n",
    "\n",
    "# Data iterators for loading the training and validation data\n",
    "train_iter = data_iterator.BatchIteratorSimple(batch_size=batch_size,\n",
    "                                               data_folder=os.path.join('..', 'data', 'train'),\n",
    "                                               image_shape=image_shape,\n",
    "                                               shift_aug=True)\n",
    "\n",
    "val_iter = data_iterator.BatchIteratorSimple(batch_size=batch_size,\n",
    "                                             data_folder=os.path.join('..', 'data', 'validation'),\n",
    "                                             image_shape=image_shape)\n",
    "\n",
    "model.fit_generator(train_iter,\n",
    "                    steps_per_epoch = 350, # the number of batches per epoch,\n",
    "                    epochs = num_epochs, # the number of epochs to train for,\n",
    "                    validation_data = val_iter, # validation iterator\n",
    "                    validation_steps = 75, # the number of batches to validate on\n",
    "                    workers = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save your trained model weights\n",
    "weight_file_name = 'model_weights'\n",
    "model.save_weights(os.path.join('..', 'data', 'weights', weight_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you need to load a model which you previously trained you can uncomment the codeline that calls the following function.\n",
    "def load_weights(your_model, your_weight_filename):\n",
    "    model_path = os.path.join('..', 'data', 'weights', your_weight_filename)\n",
    "    if os.path.exists(model_path):\n",
    "        model = your_model.load_weights(model_path)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError('No weight file found at {}'.format(model_path))\n",
    "\n",
    "# model = load_weights(model, weight_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dir_if_not_exist(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(filenames, output_path):\n",
    "    for name in file_names:\n",
    "        image = misc.imread(name)\n",
    "        if image.shape[0] != image_shape[0]:\n",
    "             image = misc.imresize(image, image_shape)\n",
    "        image = data_iterator.preprocess_input(image.astype(np.float32))\n",
    "        pred = model.predict_on_batch(np.expand_dims(image, 0))\n",
    "        base_name = os.path.basename(name).split('.')[0]\n",
    "        base_name = base_name + '_prediction.png'\n",
    "        misc.imsave(os.path.join(output_path, base_name), np.squeeze((pred * 255).astype(np.uint8)))\n",
    "\n",
    "validation_path1 = os.path.join('..', 'data', 'grading_data1', 'patrol_with_targ')\n",
    "file_names = sorted(glob.glob(os.path.join(validation_path1, 'images', '*.jpeg')))\n",
    "\n",
    "experiment_name = 'patrol_with_targ'# TODO add the name of folder to save these predictions to\n",
    "output_path1 = os.path.join('..', 'data', 'runs', experiment_name)\n",
    "make_dir_if_not_exist(output_path1)\n",
    "predict(file_names, output_path1)\n",
    "\n",
    "validation_path2 = os.path.join('..', 'data', 'grading_data1', 'patrol_non_targ')\n",
    "file_names = sorted(glob.glob(os.path.join(validation_path2, 'images', '*.jpeg')))\n",
    "\n",
    "experiment_name = 'patrol_no_targ'# TODO add the name of folder to save these predictions to\n",
    "output_path2 = os.path.join('..', 'data', 'runs', experiment_name)\n",
    "make_dir_if_not_exist(output_path2)\n",
    "predict(file_names, output_path2)\n",
    "\n",
    "validation_path3 = os.path.join('..', 'data', 'grading_data1', 'following_images')\n",
    "file_names = sorted(glob.glob(os.path.join(validation_path3, 'images', '*.jpeg')))\n",
    "\n",
    "experiment_name = 'following_image'# TODO add the name of folder to save these predictions to\n",
    "output_path3 = os.path.join('..', 'data', 'runs', experiment_name)\n",
    "make_dir_if_not_exist(output_path3)\n",
    "predict(file_names, output_path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Let's evaluate your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores for while the quad is following behind the target. \n",
    "scoring_utils.score_run_iou(validation_path3, output_path3)\n",
    "print('\\n')\n",
    "# the centroid accuracy is important to look at here. The small the centroid error the more \n",
    "# accurately the targets x,y,z coordinates can be calculated\n",
    "scoring_utils.score_run_centroid(validation_path3, output_path3)\n",
    "\n",
    "# scores for images while the quad is on patrol and the target is not visable\n",
    "scoring_utils.score_run_iou(validation_path2, output_path2)\n",
    "print('\\n')\n",
    "\n",
    "# the most important score here is the number of false positives which indicates\n",
    "# How often the network would tell the quad to go towards the wrong person\n",
    "scoring_utils.score_run_centroid(validation_path3, output_path3)\n",
    "\n",
    "# this score measures how well the neural network can detect the target from far away\n",
    "scoring_utils.score_run_iou(validation_path1, output_path1)\n",
    "print('\\n')\n",
    "\n",
    "# Here there is an emphasis on looking at the false negatives, how often does the network, miss \n",
    "# the target when they are are actually in view\n",
    "scoring_utils.score_run_centroid(validation_path1, output_path1)\n",
    "\n",
    "# additionally the centroid errors are an indicator of the accuracy of x,y,z of the targets coordinates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
